自然语言处理中的数学基础



## 概率论

### 最大似然估计 (maximum likelihood estimation) ：

​	似然，英文likelihood，口语化的直译为可能性，因此，最大似然又可以看作是最大可能性。最大似然估计所估计的是使得产生这个结果的条件或者参数，也就是说实在一个已知结果的情况下去估计具备产生这个结果的最大可能性的参数或条件。

1. 写出似然函数；
2. 对似然函数取对数，并整理；
3. 求导数，令导数为0，得到似然方程；
4. 解似然方程，得到的参数即为所求；

$$
已知有事件A，给定待估计参数A，似然估计公式为：L(B|A)，该公式L(B|A)=P(A|B=b)
$$

 	也就是在B取不同值的情况下A发生的概率，求最大似然估计就是上L(B|A)取得最大值的情况下，b的值



### 条件概率 (conditional probability) ：

设 *A* 与 *B* 为样本空间 Ω 中的两个事件，其中 *P*(*B*)>0。那么在事件 *B* 发生的条件下，事件 *A* 发生的条件概率为：

<img src="C:\Users\WELKIN\AppData\Roaming\Typora\typora-user-images\image-20211129112342912.png" alt="image-20211129112342912" style="zoom:33%;" />



### 全概率公式 (full probability) ：

**全概率定理**(Law of total probability)，假设{ *B**n* : *n* = 1, 2, 3, ... } 是一个[概率空间](https://zh.wikipedia.org/wiki/概率空間)的有限或者可数无限的[分割](https://zh.wikipedia.org/wiki/集合划分)（既 *B**n*为一完备事件组），且每个集合*B**n*是一个[可测集合](https://zh.wikipedia.org/wiki/可测集合)，则对任意事件*A*有**全概率公式**：

<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1f629ea8dda22bcc5fa6afe2d066ad753e215f2b" alt="\Pr(A)=\sum _{{n}}\Pr(A\cap B_{n})\," style="zoom: 80%;" />

又因为

<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d9fb0818b6b66cd5fe47f9e31b97421c22d7d91f" alt="\Pr(A\cap B_{n})=\Pr(A\mid B_{n})\Pr(B_{n})," style="zoom:80%;" />

此处Pr(*A* | *B*)是*B*发生后*A*的[条件概率](https://zh.wikipedia.org/wiki/条件概率)，所以**全概率公式**又可写作：

<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7929b8e24c4af9920cf0c17f5793df768d03562" alt="\Pr(A)=\sum _{{n}}\Pr(A\mid B_{n})\Pr(B_{n}).\," style="zoom:80%;" />

全概率公式将对一复杂事件A的概率求解问题转化为了在不同情况或不同原因 **Bn**下发生的简单事件的概率的求和问题



### [贝叶斯决策理论](https://www.cnblogs.com/hizhaolei/p/8196096.html#:~:text=2.1%20%E6%9C%80%E5%B0%8F%E9%94%99%E8%AF%AF%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96.%20%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA%E4%BE%9D%E6%8D%AE%E5%B0%B1%E6%98%AF%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F%EF%BC%88%E5%BC%8F1%EF%BC%89%EF%BC%8C%E7%94%B1%E6%80%BB%E4%BD%93%E5%AF%86%E5%BA%A6P%20%28E%29%E3%80%81%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87P%20%28H%29%E5%92%8C%E7%B1%BB%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87P%20%28E%7CH%29%E8%AE%A1%E7%AE%97%E5%87%BA%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87P%20%28H%7CE%29%EF%BC%8C%E5%88%A4%E5%86%B3%E9%81%B5%E4%BB%8E%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E3%80%82.,%E8%BF%99%E7%A7%8D%E4%BB%85%E6%A0%B9%E6%8D%AE%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E4%BD%9C%E5%86%B3%E7%AD%96%E7%9A%84%E6%96%B9%E5%BC%8F%E7%A7%B0%E4%B8%BA%E6%9C%80%E5%B0%8F%E9%94%99%E8%AF%AF%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BB%8E%E7%90%86%E8%AE%BA%E4%B8%8A%E8%AF%81%E6%98%8E%E8%BF%99%E7%A7%8D%E5%86%B3%E7%AD%96%E7%9A%84%E5%B9%B3%E5%9D%87%E9%94%99%E8%AF%AF%E7%8E%87%E6%98%AF%E6%9C%80%E4%BD%8E%E7%9A%84%E3%80%82.%20%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%98%AF%E8%80%83%E8%99%91%E5%86%B3%E7%AD%96%E9%A3%8E%E9%99%A9%EF%BC%8C%E5%8A%A0%E5%85%A5%E4%BA%86%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8C%E7%A7%B0%E4%B8%BA%E6%9C%80%E5%B0%8F%E9%A3%8E%E9%99%A9%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E3%80%82.%20%E2%80%A6%E2%80%A6%EF%BC%88%E5%BC%8F1%EF%BC%89.%20%E3%80%90%E8%AF%81%E6%98%8E%E3%80%91%E6%9C%80%E5%B0%8F%E9%94%99%E8%AF%AF%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E7%9A%84%E5%B9%B3%E5%9D%87%E9%94%99%E8%AF%AF%E7%8E%87%E6%9C%80%E4%BD%8E.%20%E4%BB%A5%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%BA%E4%BE%8B%EF%BC%8C%E5%AF%B9%E4%BA%8E%E6%A0%B7%E6%9C%ACx%E7%9A%84%E5%86%B3%E7%AD%96%E9%94%99%E8%AF%AF%E7%8E%87%E5%A6%82%E5%BC%8F2%EF%BC%9A.%20%E2%80%A6%E2%80%A6%EF%BC%88%E5%BC%8F2%EF%BC%89.%20%E6%9B%B4%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%BE%97%E5%88%B0%E5%BC%8F3%EF%BC%9A.) (Bayesian decision theory) ：

将分类看做决策，进行贝叶斯决策时考虑各类的先验概率和类条件概率，也即后验概率。考虑先验概率意味着对样本总体的认识，考虑类条件概率是对每一类中某个特征出现频率的认识。由此不难发现，贝叶斯决策的理论依据就是贝叶斯公式。



### 贝叶斯法则 (Bayes’ theorem)  ：

当**分析样本大到接近总体数时，样本中事件发生的概率将接近于总体中事件发生的概率。**



### 二项式分布 (binomial distribution) ：

又名伯努利分布，**两点分布**或者**0-1分布**，是一个[离散型概率分布](https://zh.wikipedia.org/wiki/概率分布#离散分布)，为纪念瑞士科学家[雅各布·伯努利](https://zh.wikipedia.org/wiki/雅各布·伯努利)而命名。若[伯努利试验](https://zh.wikipedia.org/wiki/伯努利試驗)成功，则伯努利[随机变量](https://zh.wikipedia.org/wiki/隨機變量)取值为1。若伯努利试验失败，则伯努利[随机变量](https://zh.wikipedia.org/wiki/隨機變量)取值为0。

![{\displaystyle f_{X}(x)=p^{x}(1-p)^{1-x}=\left\{{\begin{matrix}p&{\mbox{if }}x=1,\\q\ &{\mbox{if }}x=0.\\\end{matrix}}\right.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/33224c832a3cfdc7d5bb93bb37d2d3994b97f496)





### 期望 (expectation)：

在[概率论](https://zh.wikipedia.org/wiki/概率论)和[统计学](https://zh.wikipedia.org/wiki/统计学)中，一个离散性[随机变量](https://zh.wikipedia.org/wiki/随机变量)的**期望值**（或**数学期望**，亦简称**期望**，物理学中称为**期待值**）是试验中每次可能的结果乘以其结果概率的[总和](https://zh.wikipedia.org/wiki/和)。换句话说，期望值像是随机试验在同样的机会下重复多次，所有那些可能状态平均的结果，便基本上等同“期望值”所期望的数。期望值可能与每一个结果都不相等。换句话说，期望值是该变量输出值的加权平均。期望值并不一定包含于其分布值域，也并不一定等于值域平均值。



### 方差 (variance)：

在[概率论](https://zh.wikipedia.org/wiki/概率论)和[统计学](https://zh.wikipedia.org/wiki/统计学)中，一个离散性[随机变量](https://zh.wikipedia.org/wiki/随机变量)的**期望值**（或**数学期望**，亦简称**期望**，物理学中称为**期待值**）是试验中每次可能的结果乘以其结果概率的[总和](https://zh.wikipedia.org/wiki/和)。换句话说，期望值像是随机试验在同样的机会下重复多次，所有那些可能状态平均的结果，便基本上等同“期望值”所期望的数。期望值可能与每一个结果都不相等。换句话说，期望值是该变量输出值的加权平均。期望值并不一定包含于其分布值域，也并不一定等于值域平均值。



### 随机过程（stochastic process）：

在[概率论](https://zh.wikipedia.org/wiki/概率论)和[统计学](https://zh.wikipedia.org/wiki/统计学)中，一个离散性[随机变量](https://zh.wikipedia.org/wiki/随机变量)的**期望值**（或**数学期望**，亦简称**期望**，物理学中称为**期待值**）是试验中每次可能的结果乘以其结果概率的[总和](https://zh.wikipedia.org/wiki/和)。换句话说，期望值像是随机试验在同样的机会下重复多次，所有那些可能状态平均的结果，便基本上等同“期望值”所期望的数。期望值可能与每一个结果都不相等。换句话说，期望值是该变量输出值的加权平均。期望值并不一定包含于其分布值域，也并不一定等于值域平均值。



## 信息论

熵、联合熵、条件熵、相对熵、交叉熵；困惑度、互信息、